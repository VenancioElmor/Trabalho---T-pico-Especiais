{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trabalho_AVD2_Venâncio.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9l-dJqStMpB"
      },
      "source": [
        "#CARREGANDO DEPENDÊNCIAS#\n",
        "#Instalando o Pytesseract e o tesseract-OCR\n",
        "! sudo apt install tesseract-ocr\n",
        "! pip install pytesseract\n",
        "! apt-get install tesseract-ocr-por\n",
        "! tesseract --list-langs\n",
        "#Importando bibliotecas e módulos necessárias para o funcionamento do código\n",
        "import numpy as np # importando o numpy \n",
        "import pandas as pd # importando o pandas\n",
        "import cv2 # importando o cv2\n",
        "from google.colab.patches import cv2_imshow #importando o cv2 \n",
        "from skimage import io # importando skimage\n",
        "import matplotlib.pylab as plt # importando o matplotlib\n",
        "import scipy # importando o scipy\n",
        "import pytesseract # importando o pytesseract\n",
        "import shutil # importando o shutil\n",
        "import os # importando o os\n",
        "import random # importando o random\n",
        "try: \n",
        " from PIL import Image\n",
        "except ImportError:\n",
        " import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bYUOzy5u9h_"
      },
      "source": [
        "Questão 1:\n",
        "Desenvolva um código que lhe permita abrir uma imagem RGB ou BGR de sua preferência, utilizando a interface python do OpenCV. Logo depois, converta a imagem para escala de cinza e exiba as duas imagens lado a lado na tela. Documente as funções utilizadas no código"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X99QniYDvBGf"
      },
      "source": [
        "#Aqui será passado qual a imagem será lida:\n",
        "imagem = cv2.imread('/content/imagens/NZ-3.jpg')\n",
        "#Redimensionamento da imagem.\n",
        "imagem = cv2.resize (imagem, (500,400))\n",
        "#Fazendo a leitura da imagem em RGB ou BGR.\n",
        "imagem2 = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
        "#Irá posicionar as imagens lado a lado.\n",
        "imagem_final = cv2.hconcat((imagem, imagem2))\n",
        "#Mostrá a imagem\n",
        "cv2_imshow(imagem_final)\n",
        "#Irá converter a imagem escolhida para escala de cinza.\n",
        "image_PB = cv2.cvtColor(imagem2, cv2.COLOR_BGR2GRAY)\n",
        "#Vai mostrar a imagem convertida em cinza.\n",
        "cv2_imshow(image_PB)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyfRbKX003cM"
      },
      "source": [
        "Questão 2:\n",
        "Utilizando o código fonte das nossas aulas como base, carregue uma imagem contendo pelo menos uma face (pode ser a imagem carregada no item 1), depois carregue o modelo de detecção de faces utilizado nas nossas aulas anteriores. Construa um código de detecção de faces, encontre a caixa envolvente da face na imagem. Pinte o retângulo ao redor da(s) face(s) encontrada(s) e exiba a imagem pintada na tela. Documente as funções utilizadas no código."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG4h88oL099n"
      },
      "source": [
        "#Aqui será importado o classificado de faces para identificar os rostos na imagem.\n",
        "detector_facial = cv2.CascadeClassifier('/content/cascad/haarcascade_frontalface_alt2.xml')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgYsddP42V6a"
      },
      "source": [
        "#Aqui será importada a imagem para fazer a detecção facial. \n",
        "image_face = cv2.imread('/content/imagens/rostos.jpg')\n",
        "#Aqui a imagem selecionada será convertida para escala de cinza. \n",
        "image_gray = cv2.cvtColor(image_face, cv2.COLOR_BGR2GRAY)\n",
        "#Aqui iremos definir qual será o detector de face utilizado e passar seus parâmetros\n",
        "detector = detector_facial.detectMultiScale(image_gray, scaleFactor=1.1, minNeighbors=3,\n",
        "                                             minSize=(30,30), maxSize=(500,500))\n",
        "\n",
        "#Aqui iremoa criar um for através do próprio detecotr para conseguirmos desenhar as bbox e printar seu tamanho\n",
        "for (x, y, w, h) in detector:\n",
        "  print(w, h)\n",
        "  cv2.rectangle(image_face, (x, y), (x + w, y + h), (2,255,0), 2)\n",
        "#Será mostrado a imagem final com as bbox.\n",
        "cv2_imshow(image_face)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7EVmYgi7cep"
      },
      "source": [
        "3-Carregue uma imagem que contenha uma página de texto de um documento digitalizado de sua preferência. Uma vez carregada a imagem, utilize o OCR com o qual trabalhamos na nossa última aula (Tesseract), reconheça o texto, e imprima o texto reconhecido na tela. Documente as funções utilizadas no código"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aekf2n4p7dnd"
      },
      "source": [
        "#Criando um for para printar a imagem contendo um texto \n",
        "for url in urls:\n",
        "#Irá ler a imagem que possui o texto.\n",
        "image = io.imread('/content/imagens/ia.jpg') \n",
        "#Redimensionando a imagem para 800x600\n",
        "imagem = cv2.resize(image, (800, 600))\n",
        "  \n",
        "#Aqui irá ler a mensagem e printar o seu texto\n",
        "image_texto = '/content/imagens/ia.jpg'\n",
        "texto = pytesseract.image_to_string(image_texto, lang='por')\n",
        "print(texto)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}